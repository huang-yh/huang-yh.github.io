
<!DOCTYPE HTML>

<style>
  #full {
    display: none;
  }
  </style>

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Yuanhui Huang</title>
  
  <meta name="author" content="Yuanhui Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon_tsinghua.png">
</head>


<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yuanhui Huang</name>
              </p>
              <p> 
                I am a second year Ph.D student in <a href="http://ivg.au.tsinghua.edu.cn/"> i-VisionGroup </a> in the Department of Automation, Tsinghua University, advised by Prof. <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>. In 2022, I received my BS degree from the Department of Electronic Engineering, Tsinghua University.
                I am interested in computer vision and deep learning. My current research focuses on autonomous driving, representation learning and generative models.
              </p>
              <!-- <p>
              I am interested in computer vision and deep learning. My current research focuses on:
              <li style="margin: 5px;" >
                <b style="color:brown">Vision-centric autonomous driving</b> that efficiently perceives and predicts the complex 3D world based on images.
              </li>
                <li style="margin: 5px;" >
                  <b style="color:green">Omni-supervised representation learning</b> that exploits various types of supervision signals to learn discriminative and generalizable visual representations.
                </li>
                 <li style="margin: 5px;" >
                  <b style="color:orange">Explainable artificial intelligence</b> that builds comprehensible and trustworthy AI systems with high performance.
                </li>
              </p> -->
              <p style="text-align:center">
                <a href="mailto:huangyh22@mails.tsinghua.edu.cn"> Email </a> &nbsp/&nbsp
                <!-- <a href="files/CV_WenzhaoZheng.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=LKVgsk4AAAAJ"> Google Scholar </a> &nbsp/&nbsp
                <a href="https://github.com/huang-yh"> GitHub </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:50%;max-width:50%" alt="profile photo" src="images/yuanhuihuang.jpg">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <li style="margin: 5px;" >
                <b>2025-02:</b> Two papers are accepted to <a href="https://cvpr.thecvf.com/">CVPR 2025</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2024-07:</b> Two papers are accepted to <a href="https://eccv.ecva.net/Conferences/2024">ECCV 2024</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2024-02:</b> One paper on 3D occupancy prediction is accepted to <a href="https://cvpr2024.thecvf.com/">CVPR 2024</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2023-01:</b> One paper on 3D occupancy prediction is accepted to <a href="https://cvpr2023.thecvf.com/">CVPR 2023</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2022-07:</b> One paper on deep metric learning is accepted to <a href="https://eccv2022.ecva.net/">ECCV 2022</a>.
              </li>
            </p>
          </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="text-indent:20px;width:100%;vertical-align:middle">
            <p><heading>Publications</heading></p>
            <p>
              *Equal contribution &nbsp;&nbsp; <sup>†</sup>Project leader.
            </p>
          </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/GaussianFormer-2.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>GaussianFormer-2: Probabilistic Gaussian Superposition for Efficient 3D Occupancy Prediction</papertitle>
              <br> 
              <strong> Yuanhui Huang </strong>, 
              <a href="https://th.linkedin.com/in/amonnut-thammatadatrakoon-aa2a37269">Amonnut Thammatadatrakoon</a>,
              <a href="https://wzzheng.net/"> Wenzhao Zheng<sup>†</sup> </a>, 
              <a href="https://scholar.google.com/citations?user=UgadGL8AAAAJ&hl=zh-CN&oi=ao"> Yunpeng Zhang </a>, 
              <a href="https://dblp.org/pid/159/2057.html"> Dalong Du </a>, 
              <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong></em>), 2025.
              <br>
              <a href="https://arxiv.org/abs/2412.04384">[arXiv]</a> 
              <a href="https://github.com/huang-yh/GaussianFormer">[Code]</a>
              <iframe
              style="margin-left: 2px; margin-bottom:-5px;"
              frameborder="0" scrolling="0" width="91px" height="20px"
              src="https://ghbtns.com/github-btn.html?user=huang-yh&repo=GaussianFormer&type=star&count=true" >
              </iframe>
              <!-- <a href="https://wzzheng.net/GaussianFormer/">[Project Page]</a> -->
              <a href="https://zhuanlan.zhihu.com/p/13066563455">[中文解读 (in Chinese)]</a>
              <br>
              <p> GaussianFormer-2 improves GaussianFormer from a probabilistic perspective for both efficient and effective 3D semantic occupancy prediction. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/GaussianFormer.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>GaussianFormer: Scene as Gaussians for Vision-Based 3D Semantic Occupancy Prediction</papertitle>
              <br> 
              <strong> Yuanhui Huang </strong>, 
              <a href="https://wzzheng.net/"> Wenzhao Zheng<sup>†</sup> </a>, 
              <a href="https://scholar.google.com/citations?user=UgadGL8AAAAJ&hl=zh-CN&oi=ao"> Yunpeng Zhang </a>, 
              <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1"> Jie Zhou </a>, 
              <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>
              <br>
              <em>European Conference on Computer Vision (<strong>ECCV</strong></em>), 2024.
              <br>
              <a href="https://arxiv.org/abs/2405.17429">[arXiv]</a> 
              <a href="https://github.com/huang-yh/GaussianFormer">[Code]</a>
              <iframe
              style="margin-left: 2px; margin-bottom:-5px;"
              frameborder="0" scrolling="0" width="91px" height="20px"
              src="https://ghbtns.com/github-btn.html?user=huang-yh&repo=GaussianFormer&type=star&count=true" >
              </iframe>
              <a href="https://wzzheng.net/GaussianFormer/">[Project Page]</a>
              <a href="https://zhuanlan.zhihu.com/p/700833107">[中文解读 (in Chinese)]</a>
              <br>
              <p> GaussianFormer proposes the 3D semantic Gaussians as <b>a more efficient object-centric</b> representation for driving scenes compared with 3D occupancy.  </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/OccWorld.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving</papertitle>
              <br> 
              <a href="https://wzzheng.net/"> Wenzhao Zheng* </a>, 
              <a href="https://github.com/chen-wl20"> Weiliang Chen* </a>,  
              <strong> Yuanhui Huang </strong>, 
              <a href="http://boruizhang.site/"> Borui Zhang </a>, 
              <a href="https://duanyueqi.github.io/"> Yueqi Duan</a>, 
              <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>
              <br>
              <em>European Conference on Computer Vision (<strong>ECCV</strong></em>), 2024.
              <br>
              <a href="https://arxiv.org/abs/2311.16038">[arXiv]</a> 
              <a href="https://github.com/wzzheng/OccWorld">[Code]</a>
              <iframe
              style="margin-left: 2px; margin-bottom:-5px;"
              frameborder="0" scrolling="0" width="91px" height="20px"
              src="https://ghbtns.com/github-btn.html?user=wzzheng&repo=OccWorld&type=star&count=true" >
              </iframe>
              <a href="https://wzzheng.net/OccWorld/">[Project Page]</a>
              <a href="https://zhuanlan.zhihu.com/p/669979822">[中文解读 (in Chinese)]</a>
              <br>
              <p> OccWorld models the joint evolutions of 3D scenes and ego movements and paves the way for interpretable end-to-end large driving models.  </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/SelfOcc.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction</papertitle>
              <br> 
              <strong> Yuanhui Huang* </strong>, 
              <a href="https://wzzheng.net/"> Wenzhao Zheng* </a>, 
              <a href="http://boruizhang.site/"> Borui Zhang </a>, 
              <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1"> Jie Zhou </a>, 
              <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024.
              <br>
              <a href="https://arxiv.org/abs/2311.12754">[arXiv]</a>
              <a href="https://github.com/huang-yh/SelfOcc">[Code]</a>
              <iframe
              style="margin-left: 2px; margin-bottom:-5px;"
              frameborder="0" scrolling="0" width="91px" height="20px"
              src="https://ghbtns.com/github-btn.html?user=huang-yh&repo=SelfOcc&type=star&count=true" >
              </iframe>
              <a href="https://huang-yh.github.io/SelfOcc/">[Project Page]</a>
              <a href="https://zhuanlan.zhihu.com/p/677380563">[中文解读 (in Chinese)]</a>
              <br>
              <p> SelfOcc is the first self-supervised work that produces reasonable 3D occupancy for surround cameras. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/PointOcc.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>PointOcc: Cylindrical Tri-Perspective View for Point-based 3D Semantic Occupancy Prediction</papertitle>
              <br> 
              <a href="https://github.com/zuosc19"> Sicheng Zuo* </a>, 
              <a href="https://wzzheng.net/"> Wenzhao Zheng* </a>, 
              <strong> Yuanhui Huang </strong>, 
              <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1"> Jie Zhou </a>, 
              <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>
              <br>
              <em><strong>arXiv</strong></em>, 2023.
              <br>
              <a href="https://arxiv.org/abs/2308.16896">[arXiv]</a>
              <a href="https://github.com/wzzheng/PointOcc">[Code]</a>
              <iframe
              style="margin-left: 2px; margin-bottom:-5px;"
              frameborder="0" scrolling="0" width="91px" height="20px"
              src="https://ghbtns.com/github-btn.html?user=wzzheng&repo=PointOcc&type=star&count=true" >
              </iframe>
              <a href="https://zhuanlan.zhihu.com/p/668842814">[中文解读 (in Chinese)]</a>
              <br>
              <p> As the first 2D-projection-based method on the 3D semantic occupancy prediction task, PointOcc significantly outperforms all other methods by a large margin with a much faster speed. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/tpvformer.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction</papertitle>
              <br> 
              <strong> Yuanhui Huang* </strong>, 
              <a href="https://wzzheng.net/"> Wenzhao Zheng* </a>, 
              <a href="https://scholar.google.com/citations?user=UgadGL8AAAAJ&hl=zh-CN&oi=ao"> Yunpeng Zhang </a>, 
              <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1"> Jie Zhou </a>, 
              <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023.
              <br>
              <a href="https://arxiv.org/abs/2302.07817">[arXiv]</a>
              <a href="https://github.com/wzzheng/TPVFormer">[Code]</a>
              <iframe
              style="margin-left: 2px; margin-bottom:-5px;"
              frameborder="0" scrolling="0" width="100px" height="20px"
              src="https://ghbtns.com/github-btn.html?user=wzzheng&repo=TPVFormer&type=star&count=true" >
              </iframe>
              <a href="https://wzzheng.net/TPVFormer/">[Project Page]</a>
              <a href="https://zhuanlan.zhihu.com/p/614984007">[中文解读 (in Chinese)]</a>
              <br>
              <p> Given only surround-camera motorcycle RGB images barrier as inputs, our model (trained using trailer only sparse traffic cone LiDAR point supervision) can predict the semantic occupancy for all volumes in the 3D space. </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/CLCD.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Dynamic Metric Learning with Cross-Level Concept Distillation</papertitle>
              <br>
              <a href="https://wzzheng.net/"> Wenzhao Zheng </a>, 
              <strong> Yuanhui Huang </strong>, 
              <a href="http://boruizhang.site/"> Borui Zhang</a>, 
              <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1"> Jie Zhou </a>,
              <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>
              <br>
              <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2022.
              <br>
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136840194.pdf">[PDF]</a>
              <a href="https://github.com/wzzheng/CLCD">[Code]</a>
              <iframe
              style="margin-left: 2px; margin-bottom:-5px;"
              frameborder="0" scrolling="0" width="91px" height="20px"
              src="https://ghbtns.com/github-btn.html?user=wzzheng&repo=CLCD&type=star&count=true" >
              </iframe>
              <br>
              <p> This paper propose a hierarchical concept refiner to construct multiple levels of concept embeddings of an image and them pull closer the distance of the corresponding concepts to facilitate the cross-level semantic structure of the image representations. </p>
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li style="margin: 5px;"> 2023 Zhengzhou Scholarship</li>
                <li style="margin: 5px;"> 2021 Toyota Scholarship</li>
                <li style="margin: 5px;"> 2020 Zhang Mingwei Scholarship</li>
                <li style="margin: 5px;"> 2019 Meng Zhaoying Scholarship</li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Conference Reviewer:</b> CVPR 2024, ICCV 2023, NeurIPS 2023
              </li>
              <li style="margin: 5px;"> 
                <b>Journal Reviewer:</b> T-CSVT, Pattern Recognition
              </li>
            </p>
          </td>
          </tr>
        </tbody></table>
       
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
    </td></tr>
  </table>
 
<p><center>
	  <!-- <div id="clustrmaps-widget" style="width:5%">
    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=3Xl5HqLv8wQcw477KsV8mPSQEnrm59hQ6peJ0jKbxdw&cl=ffffff&w=a"></script>
	  </div>         -->
	  <br>
	    &copy; Yuanhui Huang | Last updated: July 2, 2024.
</center></p>
</body>

</html>
